{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from logRegression import LogRegression \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(model, X, y):\n",
    "    acc_scores = []\n",
    "    prec_scores = []\n",
    "    roc_scores = []\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc_score = accuracy_score(y_test, y_pred)\n",
    "        prec_score = precision_score(y_test, y_pred, pos_label='positive', average='micro')\n",
    "        roc_score = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred))\n",
    "        acc_scores.append(acc_score)\n",
    "        prec_scores.append(prec_score)\n",
    "        roc_scores.append(roc_score)\n",
    "\n",
    "    score = np.mean(acc_scores), np.mean(prec_scores), np.mean(roc_scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('newRain.csv')\n",
    "df.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "X, Y = df.drop(['RainTomorrow'], axis=1), df['RainTomorrow']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error_validation(accuracy, precission, roc_auc):\n",
    "    print('Ошибки на кросс валидации:')\n",
    "    print(f'Accuracy  = {accuracy}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Roc auc   = {roc_auc}')\n",
    "    \n",
    "def retrain(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred_test = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    acc = accuracy_score(y_pred_train, y_train), accuracy_score(y_pred_test, y_test)\n",
    "    \n",
    "    prec = precision_score(y_pred_train, y_train, pos_label='positive', average='micro'), precision_score(y_pred_test, y_test, pos_label='positive', average='micro')\n",
    "    \n",
    "    roc = roc_auc_score(pd.get_dummies(y_train), pd.get_dummies(y_pred_train)), roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred_test))\n",
    "    \n",
    "    print('Ошибки на выборках')\n",
    "    print('            Train                   Test')\n",
    "    print(f'Accuracy  = {acc[0]}  |  {acc[1]}')\n",
    "    print(f'Precision = {prec[0]}  |  {prec[1]}')\n",
    "    print(f'Roc auc   = {roc[0]}  |  {roc[1]}')\n",
    "    \n",
    "    \n",
    "def search_parametrs_C(C_list):\n",
    "    best_C = None\n",
    "    best_roc = 0\n",
    "    \n",
    "    for C in C_list:\n",
    "        model = LogisticRegression(C=C)\n",
    "        accuracy, precision, roc_auc = cross_val_score(model, X.values, Y.values)\n",
    "        if roc_auc > best_roc:\n",
    "            best_C = C\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на кросс валидации:\n",
      "Accuracy  = 0.4614\n",
      "Precision = 0.4614\n",
      "Roc auc   = 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, roc_auc = cross_val_score(model, X.values, Y.values)\n",
    "print_error_validation(accuracy, precision, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на выборках\n",
      "            Train                   Test\n",
      "Accuracy  = 0.7528571428571429  |  0.752\n",
      "Precision = 0.7528571428571429  |  0.752\n",
      "Roc auc   = 0.5  |  0.5\n"
     ]
    }
   ],
   "source": [
    "retrain(model, x_train.values, x_test.values, y_train.values, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegression(C=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на кросс валидации:\n",
      "Accuracy  = 0.5558\n",
      "Precision = 0.5558\n",
      "Roc auc   = 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy,precision,roc_auc = cross_val_score(model,X.values,Y.values)\n",
    "print_error_validation(accuracy,precision,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на выборках\n",
      "            Train                   Test\n",
      "Accuracy  = 0.7528571428571429  |  0.752\n",
      "Precision = 0.7528571428571429  |  0.752\n",
      "Roc auc   = 0.5  |  0.5\n"
     ]
    }
   ],
   "source": [
    "retrain(model, x_train.values, x_test.values, y_train.values, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "scoring = ['precision_micro', 'roc_auc','accuracy']\n",
    "scoring_test = ['test_accuracy','test_precision_micro','test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на выборках:\n",
      "Accuracy = 0.9986666666666667\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "print(f'Ошибка на выборках:\\nAccuracy = {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на кросс валидации:\n",
      "Accuracy = 0.9986666666666667 \n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionCV(cv=5,  random_state=0).fit(x_train, y_train)#multi_class='ovr',\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "print(f'Ошибки на кросс валидации:\\nAccuracy = {accuracy_score(y_test, y_pred)} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на выборках\n",
      "            Train                   Test\n",
      "Accuracy  = 0.9997142857142857  |  0.9986666666666667\n",
      "Precision = 0.9997142857142857  |  0.9986666666666667\n",
      "Roc auc   = 0.999421965317919  |  0.9982126515671471\n"
     ]
    }
   ],
   "source": [
    "retrain(logreg, x_train.values, x_test.values, y_train.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
