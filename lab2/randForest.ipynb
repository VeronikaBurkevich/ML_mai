{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from randForest import RandomForest\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(model, X,y):\n",
    "    acc_scores = []\n",
    "    prec_scores = []\n",
    "    roc_scores = []\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc_score = accuracy_score(y_test,y_pred)\n",
    "        prec_score = precision_score(y_test,y_pred)\n",
    "        roc_score = roc_auc_score(y_test,y_pred)\n",
    "        acc_scores.append(acc_score)\n",
    "        prec_scores.append(prec_score)\n",
    "        roc_scores.append(roc_score)\n",
    "\n",
    "    score = np.mean(acc_scores), np.mean(prec_scores), np.mean(roc_scores)\n",
    "    return score\n",
    "    \n",
    "def check_retrain(model,X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    acc = accuracy_score(y_pred_train,y_train), accuracy_score(y_pred_test,y_test)\n",
    "    prec = precision_score(y_pred_train,y_train), precision_score(y_pred_test,y_test)\n",
    "    roc= roc_auc_score(y_pred_train,y_train),roc_auc_score(y_pred_test,y_test)\n",
    "    print('Ошибки на выборках')\n",
    "    print('            Train                  Test')\n",
    "    print(f'Accuracy  = {acc[0]}  |  {acc[1]}')\n",
    "    print(f'Precision = {prec[0]}  |  {prec[1]}')\n",
    "    print(f'Roc auc   = {roc[0]}  |  {roc[1]}')\n",
    "    \n",
    "def print_error_validation(accuracy,precission,roc_auc):\n",
    "    print('Ошибки на валидации')\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    print(f'precision = {precision}')\n",
    "    print(f'roc auc = {roc_auc}')\n",
    "\n",
    "def search_parametrs(X,y,n_estimators_list,max_depth_list, min_size_list):\n",
    "    best_max_depth = None\n",
    "    best_min_size = None\n",
    "    best_n_estimators = None\n",
    "    best_roc = -10\n",
    "    for n_est in n_estimators_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            for min_size in min_size_list:\n",
    "                model = RandomForest(n_estimators=n_est,max_depth=max_depth,min_size=min_size)\n",
    "                accuracy,precision,roc_auc = cross_val_score(model,X,y)\n",
    "                if roc_auc > best_roc:\n",
    "                    best_n_estimators, best_max_depth, best_min_size = n_est, max_depth,min_size\n",
    "    return best_n_estimators, best_max_depth, best_min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_data = pd.read_csv('newRain1.csv')\n",
    "mobile_data.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "X, Y = mobile_data.drop(['RainTomorrow'], axis=1).values, mobile_data['RainTomorrow'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators, max_depth,min_size = search_parametrs(X,Y,n_estimators_list=np.arange(10,60,10),\n",
    "                                                    max_depth_list=np.arange(6,10,1), min_size_list=np.arange(4,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 9, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators, max_depth, min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на валидации\n",
      "accuracy = 0.61\n",
      "precision = 0.6873669467787116\n",
      "roc auc = 0.5906870906870907\n"
     ]
    }
   ],
   "source": [
    "clf =  RandomForest(n_estimators=n_estimators,max_depth=max_depth,min_size=min_size)\n",
    "accuracy,precision,roc_auc = cross_val_score(clf,X,Y)\n",
    "print_error_validation(accuracy,precision,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на выборках\n",
      "            Train                  Test\n",
      "Accuracy  = 0.6285714285714286  |  0.6666666666666666\n",
      "Precision = 0.9069767441860465  |  0.9444444444444444\n",
      "Roc auc   = 0.5974499089253188  |  0.701923076923077\n"
     ]
    }
   ],
   "source": [
    "check_retrain(clf,x_train,x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scoring = ['precision_macro', 'roc_auc','accuracy']\n",
    "scoring_test = ['test_accuracy','test_precision_macro','test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79127\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': array([6, 7, 8, 9]),\n",
       "                         'min_samples_leaf': array([4, 5, 6, 7]),\n",
       "                         'n_estimators': array([10, 20, 30, 40, 50])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "parameters = {'n_estimators':np.arange(10,60,10),'max_depth':np.arange(6,10,1), 'min_samples_leaf':np.arange(4,8,1)}\n",
    "clf_cv = GridSearchCV(clf, parameters)\n",
    "clf_cv.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=40,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators, max_depth, min_size = 40, 6, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy = 1.0\n",
      "test_precision_macro = 1.0\n",
      "test_roc_auc = 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth, min_samples_leaf=min_size)\n",
    "scores = cross_validate(clf,X,Y,cv=5,scoring=scoring)\n",
    "\n",
    "for score in scoring_test:\n",
    "    print(f'{score} = {np.mean(scores[score])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки на выборках\n",
      "            Train                  Test\n",
      "Accuracy  = 1.0  |  1.0\n",
      "Precision = 1.0  |  1.0\n",
      "Roc auc   = 1.0  |  1.0\n"
     ]
    }
   ],
   "source": [
    "check_retrain(clf,x_train,x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
